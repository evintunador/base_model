{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea126987-59aa-4f76-b926-6d632887c30b",
   "metadata": {},
   "source": [
    "# This notebook is designed for teaching purposes to help you visualize the tensor shapes that go through each module. Read along with 'model.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60c3f773-508c-4b13-8cfe-4f4b5a8907e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my virtual environments are rarely properly connected to jupyter so this fixes that\n",
    "import sys\n",
    "import os\n",
    "current_dir = os.getcwd()  # Get the current working directory\n",
    "venv_dir = os.path.join(current_dir, '../venv') \n",
    "python_version = str(sys.version_info.major) + '.' + str(sys.version_info.minor)\n",
    "site_packages_path = os.path.join(venv_dir, 'lib', 'python' + python_version, 'site-packages')\n",
    "sys.path.append(site_packages_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72c2c04f-2dbd-4020-8d91-cc0e4e8511b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "sys.path.append(\"..\")  # Adds the parent directory to the path so we can see the tokenizer\n",
    "from tokenizer_TinyStories import *\n",
    "size = 512 # size options are 128, 256, 512 and 1024\n",
    "path = f'../tokenizers/tiny_stories_tokenizer_{size}.model'\n",
    "tokenizer = get_tokenizer(path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f75e6aaf-e17f-4121-86ad-b577a6bbc875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config(dim=128, n_layers=8, vocab_size=None, norm_eps=1e-05, device='cpu', mlp_hidden_mult=4, mlp_bias=False, gated=True, nonlinearity='GeLU', n_q_heads=4, n_kv_heads=1, rope_theta=10000, max_seq_len=512, norm_type='RMSNorm', norm_affine=True, norm_bias=False, max_batch_size=32, memory_saver_div=8) <bound method Config.context_chunk of Config(dim=128, n_layers=8, vocab_size=None, norm_eps=1e-05, device='cpu', mlp_hidden_mult=4, mlp_bias=False, gated=True, nonlinearity='GeLU', n_q_heads=4, n_kv_heads=1, rope_theta=10000, max_seq_len=512, norm_type='RMSNorm', norm_affine=True, norm_bias=False, max_batch_size=32, memory_saver_div=8)>\n"
     ]
    }
   ],
   "source": [
    "# config file\n",
    "from config import *\n",
    "cfg = Config()\n",
    "print(cfg, cfg.context_chunk)\n",
    "\n",
    "# model modules\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e190f3de-37fd-442b-bfb1-6a090115fc75",
   "metadata": {},
   "source": [
    "# Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8f27b4-6d1f-4fcd-99b0-2284e65d6b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of multi-head self-attention\n",
    "module = MHSA(config)\n",
    "\n",
    "# Initially, logging is disabled by default\n",
    "module.enable_logging()\n",
    "\n",
    "### Optionally disabling printing for sub-functions\n",
    "#module.disable_function_logging('apply_rotary_emb')\n",
    "#module.disable_function_logging('reshape_for_broadcast')\n",
    "#module.disable_function_logging('match_headcount')\n",
    "#module.disable_function_logging('attend')\n",
    "#module.disable_function_logging('calc_output')\n",
    "\n",
    "# precompute RoPE frequencies, a\n",
    "\n",
    "# Call the forward method - logging will occur\n",
    "output = module(torch.randn(32,config.max_seq_len,config.embed_dim))#, training=True)\n",
    "\n",
    "# Disable logging. \n",
    "# This isn't actually necessary since we won't be using this object again but that's how you'd do it\n",
    "module.disable_logging()\n",
    "\n",
    "# clearing up ram jic we're training later\n",
    "del module, output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
