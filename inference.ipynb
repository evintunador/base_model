{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c8178ba-2ea0-4f4f-b9ca-c3435a83bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my virtual environments are rarely properly connected to jupyter so this fixes that. \n",
    "# you prolly won't need this cell but running it won't hurt anything either\n",
    "import sys\n",
    "import os\n",
    "current_dir = os.getcwd()  # Get the current working directory\n",
    "venv_dir = os.path.join(current_dir, 'venv') \n",
    "python_version = str(sys.version_info.major) + '.' + str(sys.version_info.minor)\n",
    "site_packages_path = os.path.join(venv_dir, 'lib', 'python' + python_version, 'site-packages')\n",
    "sys.path.append(site_packages_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0918a651-5c6a-4a39-8b3e-a28259e4fd64",
   "metadata": {},
   "source": [
    "# Load a Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39c0ba50-83de-4ad7-b262-944e6d547ae9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load_model() missing 1 required positional argument: 'tokenizer_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/customGPT/trained/customGPT_4m_SwiGLU\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[0;32m---> 15\u001b[0m model, tokenizer, cfg \u001b[38;5;241m=\u001b[39m load_model(name)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# If you only plan to do inference, switch to evaluation mode\u001b[39;00m\n\u001b[1;32m     18\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[0;31mTypeError\u001b[0m: load_model() missing 1 required positional argument: 'tokenizer_name'"
     ]
    }
   ],
   "source": [
    "# pretrained model options:\n",
    "# a 1m parameter model trained for 2000 iters with many layers, thin MLP hidden dimensions & few attention heads: 'models/customGPT/trained/customGPT_1m_tall_and_skinny'\n",
    "# a 1m parameter model trained for 2000 iters with layers, MLP hidden dimensions, & attention heads bw the other two: 'models/customGPT/trained/customGPT_1m_5ft11_and_skinnyfat'\n",
    "# a 1m parameter model trained for 2000 iters with few layers, thick MLP hidden dimensions & many attention heads: 'models/customGPT/trained/customGPT_1m_short_and_thicc'\n",
    "# a 2m parameter model trained for 4000 iters with CosineNorm: 'models/customGPT/trained/customGPT_2m_CosineNorm'\n",
    "# a 2m parameter model trained for 4000 iters with LayerNorm: 'models/customGPT/trained/customGPT_2m_LayerNorm'\n",
    "# a 2m parameter model trained for 4000 iters with RMSNorm: 'models/customGPT/trained/customGPT_2m_RMSNorm'\n",
    "# a 3m parameter model trained for 5000 iters with a gated MLP: 'models/customGPT/trained/customGPT_3m_GatedMLP'\n",
    "# a 3m parameter model trained for 5000 iters with an old-fashioned MLP: 'models/customGPT/trained/customGPT_3m_GatedMLP'\n",
    "# a 4m parameter model trained for 6000 iters with GeGLU activation: 'models/customGPT/trained/customGPT_4m_GeGLU'\n",
    "# a 4m parameter model trained for 6000 iters with SwiGLU activation: 'models/customGPT/trained/customGPT_4m_SwiGLU'\n",
    "name = 'models/customGPT/trained/customGPT_4m_SwiGLU'\n",
    "\n",
    "from tools import load_model\n",
    "model, tokenizer, cfg = load_model(name)\n",
    "\n",
    "# If you only plan to do inference, switch to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c971fce-8b3e-4732-bd66-d5d2028025d6",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a366b1fc-b620-45a0-8b42-71bdca18906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c202ea0-e64d-4367-a4a6-102756fe63b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On|ce| |up|on |a |ti|me|, |the|re| |was| a| bo|y |na|me|d |Tim|. \n"
     ]
    }
   ],
   "source": [
    "prompt = \"Once upon a time, there was a boy named Tim. \"\n",
    "print(tokenizer.display(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5b13a76-50f8-48b6-b7cf-9097d307c6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum attention matrix size in memory will be 64x512 rather than 512x512\n",
      "\n",
      "Once upon a time, there was a boy named Tim. He saw a big park to cover and loved to play with a car friends. One day, Tim went to the know what with a big cready to bull and it was a new was very happy and jumped to see. He asked Lily it, something unexpected to play on, something smiled and said, \"What wanted to play.\n",
      "Then, he was not fire it was sad. She was very happy lots with a dog. They were sad. They played the very happy. He went the rung a big, Tim was so happy. He didn't know when a little good friends, and stars and the toy. They was very happy the garden.\n"
     ]
    }
   ],
   "source": [
    "output = generate(\n",
    "    prompt, \n",
    "    model, \n",
    "    tokenizer,\n",
    "    #max_gen_len = 100,\n",
    "    temperature = 0.7,\n",
    "    memory_saver_div = 8,\n",
    "    top_p = 0.9,\n",
    "    top_k = 32,\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114de8bf-ab76-460d-8c37-ebe368b47e90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
