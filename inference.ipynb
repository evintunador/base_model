{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c8178ba-2ea0-4f4f-b9ca-c3435a83bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my virtual environments are rarely properly connected to jupyter so this fixes that. \n",
    "# you won't need this cell but running it won't hurt anything either\n",
    "import sys\n",
    "import os\n",
    "current_dir = os.getcwd()  # Get the current working directory\n",
    "venv_dir = os.path.join(current_dir, './venv') \n",
    "python_version = str(sys.version_info.major) + '.' + str(sys.version_info.minor)\n",
    "site_packages_path = os.path.join(venv_dir, 'lib', 'python' + python_version, 'site-packages')\n",
    "sys.path.append(site_packages_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8eae0015-a5c6-493e-832a-0cfcb0ef128c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LoggingModule' from partially initialized module 'tools' (most likely due to a circular import) (/home/tunadorable/Documents/base_model/tools.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minference\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n",
      "File \u001b[0;32m~/Documents/base_model/tools.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataclasses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m asdict\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m customGPT\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelConfig\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtokenizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_tokenizer\n",
      "File \u001b[0;32m~/Documents/base_model/model.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoggingModule\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelConfig\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m###########################################################\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#################### NORM ##################################\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m###########################################################\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'LoggingModule' from partially initialized module 'tools' (most likely due to a circular import) (/home/tunadorable/Documents/base_model/tools.py)"
     ]
    }
   ],
   "source": [
    "from inference import generate\n",
    "from tools import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0918a651-5c6a-4a39-8b3e-a28259e4fd64",
   "metadata": {},
   "source": [
    "# Load a Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39c0ba50-83de-4ad7-b262-944e6d547ae9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# pretrained model options:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# - a 1.5m parameter that hasn't really been trained, just a test: customGPT_2024-04-25|10-16-11\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# - a 1m parameter model trained for 500 iters with warmup 50, lr_init 0.01, lr_final 1e-5, weight_decay 0.02: customGPT_2024-04-25|15-58-37\u001b[39;00m\n\u001b[1;32m      4\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustomGPT_2024-04-25|15-58-37\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 6\u001b[0m model, tokenizer, cfg \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m(name)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# If you only plan to do inference, switch to evaluation mode\u001b[39;00m\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_model' is not defined"
     ]
    }
   ],
   "source": [
    "# pretrained model options:\n",
    "# - a 1.5m parameter that hasn't really been trained, just a test: customGPT_2024-04-25|10-16-11\n",
    "# - a 1m parameter model trained for 500 iters with warmup 50, lr_init 0.01, lr_final 1e-5, weight_decay 0.02: customGPT_2024-04-25|15-58-37\n",
    "name = 'customGPT_2024-04-25|15-58-37'\n",
    "\n",
    "model, tokenizer, cfg = load_model(name)\n",
    "\n",
    "# If you only plan to do inference, switch to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c971fce-8b3e-4732-bd66-d5d2028025d6",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3af2d78a-1d5b-42eb-85ad-0e486deb314a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a little boy named Tim. Tim loved to play with his toys. One day, Tim found a big dog came to the park. Tim was very happy and you wanted to help it. Tim was very happy. Tim was very happy and and played with it. Tim was happy to do the day, but they got to play with the ball. Tim was very happy and came on the ball and went to play with the ball.\n",
      "Tim was very happy and put the tower to the floor. The dog was very happy and the bird was too clapp\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Once\"\n",
    "output = generate(\n",
    "    prompt, \n",
    "    model, \n",
    "    tokenizer,\n",
    "    #max_gen_len = 100,\n",
    "    #temperature = 0.7,\n",
    "    #memory_saver_div = 8,\n",
    "    #top_p = 0.9,\n",
    "    #top_k = 32,\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ff56cce-bf34-4dbf-9feb-ff8daccf3f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum attention matrix size in memory will be 64x512 rather than 512x512\n",
      "\n",
      "Once upon a time, there was a little boy named Tim. Tim was a green every day. He liked to play with his mom. One day, he saw a big cat and went to the butch. Tim was very happy and the ball. Tim was very sad and the butter to the park with the he on the store. Tim said, \"Hello, Tim, can is you make can and said, \"Let's play with the bird. I knew marst the table and said, \"No, Tim, this ball to make up and went to the magic and on the tree. They all played together and play with the ground and the bird were very happy. They were happy to the work and found a fun day to the bee with his friends.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Once\"\n",
    "output = generate(\n",
    "    prompt, \n",
    "    model, \n",
    "    tokenizer,\n",
    "    #max_gen_len = 100,\n",
    "    #temperature = 0.7,\n",
    "    memory_saver_div = 8,\n",
    "    #top_p = 0.9,\n",
    "    #top_k = 32,\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f991cea-9d2d-4382-8443-9a134d6c78d4",
   "metadata": {},
   "source": [
    "# perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2ffc4d-1482-4be0-ba29-a3f2f7c5947d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
