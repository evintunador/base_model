{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c8178ba-2ea0-4f4f-b9ca-c3435a83bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my virtual environments are rarely properly connected to jupyter so this fixes that. \n",
    "# you won't need this cell but running it won't hurt anything either\n",
    "import sys\n",
    "import os\n",
    "current_dir = os.getcwd()  # Get the current working directory\n",
    "venv_dir = os.path.join(current_dir, './venv') \n",
    "python_version = str(sys.version_info.major) + '.' + str(sys.version_info.minor)\n",
    "site_packages_path = os.path.join(venv_dir, 'lib', 'python' + python_version, 'site-packages')\n",
    "sys.path.append(site_packages_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0918a651-5c6a-4a39-8b3e-a28259e4fd64",
   "metadata": {},
   "source": [
    "# Load a Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39c0ba50-83de-4ad7-b262-944e6d547ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelConfig(dim=64, vocab_len=2051, device='cpu', num_layers=10, second_resid_norm=False, mlp_hidden_mult=1, mlp_bias=False, mlp_nonlinearity='SiLU', mlp_gated=True, num_q_heads=10, num_kv_heads=2, head_dim=16, theta=10000, max_seq_len=512, scale_first_resid=True, norm_type='RMSNorm', norm_affine=True, norm_bias=True, eps=1e-06, max_batch_size=1) \n",
      "\n",
      " 502.592 K parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "baseGPT(\n",
       "  (token_embedder): Embedding(2051, 64)\n",
       "  (layers): ModuleList(\n",
       "    (0-9): 10 x ResidualLayer(\n",
       "      (pre_attn_norm): Norm()\n",
       "      (attn): MQSA(\n",
       "        (Wq): Linear(in_features=64, out_features=160, bias=False)\n",
       "        (Wk): Linear(in_features=64, out_features=32, bias=False)\n",
       "        (Wv): Linear(in_features=64, out_features=32, bias=False)\n",
       "        (Wo): Linear(in_features=160, out_features=64, bias=False)\n",
       "      )\n",
       "      (pre_mlp_norm): Norm()\n",
       "      (mlp): MLP(\n",
       "        (Wgate): Linear(in_features=64, out_features=64, bias=False)\n",
       "        (Wup): Linear(in_features=64, out_features=64, bias=False)\n",
       "        (Wdown): Linear(in_features=64, out_features=64, bias=False)\n",
       "        (nonlinearity): SiLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_norm): Norm()\n",
       "  (criterion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pretrained model options:\n",
    "# - a 0.5m parameter model trained for 1000 iters: 'baseGPT_0.5m_tall_and_skinny'\n",
    "# - a 0.5m parameter model trained for 1000 iters: 'baseGPT_0.5m_5foot11_and_skinnyfat'\n",
    "# - a 0.5m parameter model trained for 1000 iters: 'baseGPT_0.5m_short_and_thick'\n",
    "name = 'baseGPT_0.5m_tall_and_skinny'\n",
    "\n",
    "from tools import load_model\n",
    "model, tokenizer, cfg = load_model(name)\n",
    "\n",
    "# If you only plan to do inference, switch to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c971fce-8b3e-4732-bd66-d5d2028025d6",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3af2d78a-1d5b-42eb-85ad-0e486deb314a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum attention matrix size in memory will be 64x512 rather than 512x512\n",
      "\n",
      "Once upon a time, there was a little girl named Lily. She saw a small house and day and were not loys to his mom. She was very not wind mom and said, \"Hi, she was not mom could on the Tim saw the mom, she was not lot her down. She said, \"Yes, I am you came and car friends. She jumped and the bird. The smiled and said, \"No, I am so happy. Sue was was very garden. They went to the playing to played to the water the frog. They played the tree and were surpris the up the bird. She started and each more. They were very very happy and said, \"I can we cat the park, and was not the box again. The toy car was sad, and was very happy and he could not more. They said, \"You are you are with her you are away.\n",
      "The bird was was a play and with the put of the broue together.\n"
     ]
    }
   ],
   "source": [
    "from inference import generate\n",
    "prompt = \"Once upon a time\"\n",
    "output = generate(\n",
    "    prompt, \n",
    "    model, \n",
    "    tokenizer,\n",
    "    #max_gen_len = 100,\n",
    "    temperature = 0.7,\n",
    "    memory_saver_div = 8,\n",
    "    top_p = 0.9,\n",
    "    top_k = 32,\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2ffc4d-1482-4be0-ba29-a3f2f7c5947d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
