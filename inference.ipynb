{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c8178ba-2ea0-4f4f-b9ca-c3435a83bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my virtual environments are rarely properly connected to jupyter so this fixes that. \n",
    "# you prolly won't need this cell but running it won't hurt anything either\n",
    "import sys\n",
    "import os\n",
    "current_dir = os.getcwd()  # Get the current working directory\n",
    "venv_dir = os.path.join(current_dir, 'venv') \n",
    "python_version = str(sys.version_info.major) + '.' + str(sys.version_info.minor)\n",
    "site_packages_path = os.path.join(venv_dir, 'lib', 'python' + python_version, 'site-packages')\n",
    "sys.path.append(site_packages_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0918a651-5c6a-4a39-8b3e-a28259e4fd64",
   "metadata": {},
   "source": [
    "# Load a Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39c0ba50-83de-4ad7-b262-944e6d547ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelConfig(dim=64, vocab_len=2051, device='cpu', num_layers=10, second_resid_norm=False, mlp_hidden_mult=1, mlp_bias=False, mlp_nonlinearity='SiLU', mlp_gated=True, num_q_heads=10, num_kv_heads=2, head_dim=16, theta=10000, max_seq_len=512, scale_first_resid=True, norm_type='RMSNorm', norm_affine=True, norm_bias=True, eps=1e-06, max_batch_size=1) \n",
      "\n",
      " 502.592 K parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (token_embedder): Embedding(2051, 64)\n",
       "  (layers): ModuleList(\n",
       "    (0-9): 10 x Layer(\n",
       "      (pre_attn_norm): Norm()\n",
       "      (attn): MQA(\n",
       "        (Wq): Linear(in_features=64, out_features=160, bias=False)\n",
       "        (Wk): Linear(in_features=64, out_features=32, bias=False)\n",
       "        (Wv): Linear(in_features=64, out_features=32, bias=False)\n",
       "        (Wo): Linear(in_features=160, out_features=64, bias=False)\n",
       "      )\n",
       "      (pre_mlp_norm): Norm()\n",
       "      (mlp): MLP(\n",
       "        (Wgate): Linear(in_features=64, out_features=64, bias=False)\n",
       "        (Wup): Linear(in_features=64, out_features=64, bias=False)\n",
       "        (Wdown): Linear(in_features=64, out_features=64, bias=False)\n",
       "        (nonlinearity): SiLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_norm): Norm()\n",
       "  (criterion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pretrained model options:\n",
    "# - a 0.5m parameter model trained for 1000 iters: 'customGPT_0.5m_tall_and_skinny'\n",
    "# - a 0.5m parameter model trained for 1000 iters: 'customGPT_0.5m_5foot11_and_skinnyfat'\n",
    "# - a 0.5m parameter model trained for 1000 iters: 'customGPT_0.5m_short_and_thick'\n",
    "name = 'customGPT_0.5m_tall_and_skinny'\n",
    "\n",
    "from tools import load_model\n",
    "model, tokenizer, cfg = load_model(name)\n",
    "\n",
    "# If you only plan to do inference, switch to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c971fce-8b3e-4732-bd66-d5d2028025d6",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a366b1fc-b620-45a0-8b42-71bdca18906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c202ea0-e64d-4367-a4a6-102756fe63b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On|ce| |up|on |a |ti|me|, |the|re| |was| a| bo|y |na|me|d |Tim|. \n"
     ]
    }
   ],
   "source": [
    "prompt = \"Once upon a time, there was a boy named Tim. \"\n",
    "print(tokenizer.display(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5b13a76-50f8-48b6-b7cf-9097d307c6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum attention matrix size in memory will be 64x512 rather than 512x512\n",
      "\n",
      "Once upon a time, there was a boy named Tim. He saw a big park to cover and loved to play with a car friends. One day, Tim went to the know what with a big cready to bull and it was a new was very happy and jumped to see. He asked Lily it, something unexpected to play on, something smiled and said, \"What wanted to play.\n",
      "Then, he was not fire it was sad. She was very happy lots with a dog. They were sad. They played the very happy. He went the rung a big, Tim was so happy. He didn't know when a little good friends, and stars and the toy. They was very happy the garden.\n"
     ]
    }
   ],
   "source": [
    "output = generate(\n",
    "    prompt, \n",
    "    model, \n",
    "    tokenizer,\n",
    "    #max_gen_len = 100,\n",
    "    temperature = 0.7,\n",
    "    memory_saver_div = 8,\n",
    "    top_p = 0.9,\n",
    "    top_k = 32,\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114de8bf-ab76-460d-8c37-ebe368b47e90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
