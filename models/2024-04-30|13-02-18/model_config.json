{"dim": 64, "vocab_len": 4099, "device": "cpu", "num_layers": 4, "second_resid_norm": false, "mlp_hidden_mult": 3, "mlp_bias": true, "mlp_nonlinearity": "GeLU", "mlp_gated": true, "num_q_heads": 8, "num_kv_heads": 1, "theta": 10000, "max_seq_len": 256, "scale_first_resid": true, "norm_type": "RMSNorm", "norm_affine": true, "norm_bias": true, "eps": 1e-06, "max_batch_size": 1}