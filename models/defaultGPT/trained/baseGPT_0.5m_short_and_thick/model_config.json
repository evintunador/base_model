{"dim": 64, "vocab_len": 2051, "device": "cpu", "num_layers": 4, "second_resid_norm": false, "mlp_hidden_mult": 4, "mlp_bias": false, "mlp_nonlinearity": "SiLU", "mlp_gated": true, "num_q_heads": 16, "num_kv_heads": 4, "head_dim": 16, "theta": 10000, "max_seq_len": 512, "scale_first_resid": true, "norm_type": "RMSNorm", "norm_affine": true, "norm_bias": true, "eps": 1e-06, "max_batch_size": 1}