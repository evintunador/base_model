{"dim": 32, "vocab_len": 1027, "device": "cpu", "num_layers": 2, "pre_connect_dropout": false, "second_resid_norm": false, "mlp_hidden_mult": 2, "mlp_bias": false, "mlp_nonlinearity": "GeLU", "mlp_gated": true, "num_q_heads": 4, "num_kv_heads": 1, "theta": 10000, "max_seq_len": 128, "scale_first_resid": true, "norm_type": "RMSNorm", "norm_affine": true, "norm_bias": true, "eps": 1e-06, "max_batch_size": 1}