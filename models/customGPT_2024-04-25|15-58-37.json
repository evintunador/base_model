{"dim": 64, "vocab_len": 1027, "device": "cpu", "num_layers": 12, "pre_connect_dropout": false, "second_resid_norm": true, "mlp_hidden_mult": 4, "mlp_bias": true, "mlp_nonlinearity": "GeLU", "mlp_gated": true, "num_q_heads": 4, "num_kv_heads": 1, "theta": 10000, "max_seq_len": 512, "scale_first_resid": true, "norm_type": "RMSNorm", "norm_affine": true, "norm_bias": true, "eps": 1e-06, "max_batch_size": 1}